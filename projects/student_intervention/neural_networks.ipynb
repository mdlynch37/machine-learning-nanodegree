{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Side notes \n",
    "_(code snippets, summaries, resources, etc.)_\n",
    "\n",
    "__Further reading:__  ( \\* = sources that have been integrated in this notebook)\n",
    "- Used Udacity forum post and [this college course handout](http://www.idi.ntnu.no/~keithd/classes/advai/lectures/backprop.pdf) to get Sigmoid Programming Exercise working\n",
    "- Useful Python code explanation of neural nets: [Neural Networks in Python](https://rolisz.ro/2013/04/18/neural-networks-in-python/)\n",
    "- From Coursera/Standford's [Machine Learning course](https://www.coursera.org/learn/machine-learning):\n",
    "    - [Neural Networks: Representation](https://www.coursera.org/learn/machine-learning/home/week/4)\n",
    "    - [Neural Networks: Learning](https://www.coursera.org/learn/machine-learning/home/week/5)\n",
    "- [Github repo](https://github.com/mdlynch37/gradient_descent.git) (forked by mdlynch37) of Jupyter notebook based on gradient descent section of Stanford course\n",
    "- \\*Provides extra explanation helpful for mini-project: [_Neural Networks_ PDF by Udactiy]( https://www.evernote.com/shard/s37/nl/1033921335/50316007-f4a1-430e-a914-db8458a7830d/) (Evernote)\n",
    "- \\* [_Data Science from Scratch_ by Joel Grus (2016)](https://www.evernote.com/shard/s37/nl/1033921335/64072b2a-f2b7-4409-9d02-611bfc0f4901/) (Evernote)\n",
    "    - Chapter 18: Neural Networks\n",
    "    - Chapter 8: Gradient Descent\n",
    "- [_Gradient Descent - Problem of Hiking Down a Mountain_ PDF worksheet by Udactiy]( https://www.evernote.com/shard/s37/nl/1033921335/f754539a-a88e-4ac1-85f3-dd5d705e4d37/) (Evernote)\n",
    "- Calculus used for Sigmoid Function below is explained at [WolframMathWorld](http://mathworld.wolfram.com/SigmoidFunction.html)\n",
    "- `sklearn`'s [Stochastic Gradient Descent module](http://scikit-learn.org/stable/modules/sgd.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of topics covered\n",
    "![summary of neural networks](neural_networks_images/summary_neural_networks.png)\n",
    "\n",
    "\n",
    "\n",
    "Two rules for neural network units:\n",
    "1. Threshold (perceptrons)\n",
    "- Delta rule (gradient descent, using the sigmoid function on perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptrons\n",
    "- Type of _neural net unit_ that:\n",
    "    - Approximates a single neuron with _n binary inputs_. \n",
    "    - Computes a weighted sum of its inputs and “fires” if that weighted sum is zero or greater\n",
    "\n",
    "![neural network in brain](neural_networks_images/neural_network_brain.png)\n",
    "\n",
    "![artificial neural network](neural_networks_images/artificial_neural_network.png)\n",
    "\n",
    "#### Mathematically, the perceptron computes output according to the following rule:\n",
    "![perceptron rule formula](neural_networks_images/perceptron_rule_formula.png)\n",
    "\n",
    "We can think of the perceptron as a hyperplane in n dimensions, perpendicular to the vector _w_ = (_w<sub>1</sub>, w<sub>2</sub>, . . . , w<sub>n</sub>_). The perceptron classifies things on one side of the hyperplane as positive and things on the other side as negative.\n",
    "\n",
    "### Power of a perceptron unit\n",
    "![perceptron power](neural_networks_images/perceptron_power.png)\n",
    "\n",
    "- Generalized to _halfplanes_\n",
    "- Perceptrons will always be linear functions that compute hyperplanes\n",
    "\n",
    "### Boolean logic with perceptrons\n",
    "- Perceptrons with certain combinations of weights and inputs act behave as a kind of \"logic gate\"\n",
    "- These perceptrons can be combined to represent any boolean operator\n",
    "- Particularly helpful for overcoming decision tree's problem with parity, i.e. `XOR` operator (see below)\n",
    "\n",
    "![perceptron boolean AND](neural_networks_images/perceptron_and.png)\n",
    "\n",
    "![perceptron boolean OR](neural_networks_images/perceptron_or.png)\n",
    "\n",
    "![perceptron boolean NOT](neural_networks_images/perceptron_not.png)\n",
    "\n",
    "![perceptron boolean XOR](neural_networks_images/perceptron_xor.png)\n",
    "\n",
    "__Summary graph__\n",
    "![perceptron boolean summary](neural_networks_images/perceptron_boolean_summary.png)\n",
    "\n",
    "### Feed-Forward Neural Networks\n",
    "The topology of a NN is enormously complicated, so it is often approximated with an idealized feed-forward neural network of discrete layers of neurons, each connected to the next. This typically entails:\n",
    "- an _input layer_ that\n",
    "    - receives inputs and feeds them forward unchanged\n",
    "- one or more _“hidden layers”_\n",
    "    - each of which consists of neurons that take the outputs of the previous layer\n",
    "    - performs some calculation, and \n",
    "    - passes the result to the next layer\n",
    "- an output layer\n",
    "    - which produces the final outputs.\n",
    "- each noninput neuron has a weight corresponding to each of its inputs and _a bias_, which is always 1 so that it can take on the threshold during the dot product operation (shown in drawn diagram below).\n",
    "- for each neuron, we’ll sum up the products of its inputs and its weights.\n",
    "- To make a thresholds in perceptron differentiable, rather than outputting the step_function applied to that product, we’ll output a smooth approximation of the step function. using the _sigmoid function_\n",
    "\n",
    "![step function vs sigmoid](neural_networks_images/step_vs_sigmoid.png)\n",
    "\n",
    "\n",
    "By using a hidden layer, we are able to feed the output of an \"and\" neuron and the output of an \"or\" neuron into a second input but not first \"input” neuron. The result is a network that performs \"or, but not and,” which is precisely XOR:\n",
    "\n",
    "![hidden layer for XOR](neural_networks_images/hidden_layer_for_xor.png)\n",
    "\n",
    "Imagine we have a training set that consists of input vectors and corresponding target output vectors. For example, in our previous xor_network example, the input vector [1, 0] corresponded to the target output [1]. And imagine that our network has some set of weights.\n",
    "\n",
    "__We then adjust the weights using the following algorithm:__\n",
    "1. Run feed_forward on an input vector to produce the outputs of all the neurons in the network.\n",
    "- This results in an error for each output neuron — the difference between its output and its target.\n",
    "- Compute the gradient of this error as a function of the neuron’s weights, and adjust its weights in the direction that most decreases the error.\n",
    "- “Propagate” these output errors backward to infer errors for the hidden layer.\n",
    "- Compute the gradients of these errors and adjust the hidden layer’s weights in the same manner.\n",
    "Typically we run this algorithm many times for our entire training set until the network converges (see code that follows in _Data Science from Scratch_)\n",
    "\n",
    "__Why use sigmoid instead of the simpler step_function?__ \n",
    "In order to train a neural network, we’ll need to use calculus, and in order to use calculus, we need smooth functions. The step function isn’t even continuous, and sigmoid is a good smooth approximation of it.\n",
    "\n",
    "Note: Technically sigmoid” refers to the shape of the function, logistic” to this particular function although people often use the terms interchangeably."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Neural Networks\n",
    "- That is, _given examples_, find weights that map inputs to outputs\n",
    "- Rules for training covered below are\n",
    "    1. Perceptron rule (with thresholds)\n",
    "    - Gradient descent or delta rule (unthresholded)\n",
    "\n",
    "### Perceptron rule\n",
    "- Binary output _is_ determined by a threshold\n",
    "- __Geometrically, we might think of training as rotating the hyperplane to put the training data on the correct side of the boundary.__\n",
    "- If data is _linearly separable_, the algorithm below will find it! (in a finite number of iterations).\n",
    "- Algorithm has to be terminated when the weight value is no longer changed at each iteration, i.e. `actual y == y-hat`\n",
    "- It can be hard to tell if data is linearly separable, especially with lots of dimensions\n",
    "- If this algorithm does not terminate for a while, this could mean data is not linearly separable, but since _finite_ could be any number, we cannot be certain of that.\n",
    "    - \"if we could solve the halting problem, we could solve this, but not necessarily so that problem could be solved another way...\"\n",
    "\n",
    "\n",
    "\n",
    "![perceptron rule calculation part 1](neural_networks_images/perceptron_rule_calc_1.png)\n",
    "![perceptron rule algorithm part 2](neural_networks_images/perceptron_rule_calc_2.png)\n",
    "![perceptron rule algorithm part 3](neural_networks_images/perceptron_rule_calc_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent\n",
    "(From _Data Science from Scratch_ Chapter 8 on topic)\n",
    "- “Frequently when doing data science, we’ll be trying to the find the best model for a certain situation. And usually “best” will mean something like “minimizes the error of the model” or “maximizes the likelihood of the data.” In other words, it will represent the solution to some sort of optimization problem.”\n",
    "- “This means we’ll need to solve a number of optimization problems. And in particular, we’ll need to solve them from scratch. Our approach will be a technique called gradient descent, which lends itself pretty well to a from-scratch treatment. You might not find it super exciting in and of itself, but it will enable us to do exciting things throughout the book, so bear with me.”\n",
    "\n",
    "#### The Idea Behind Gradient Descent\n",
    "\"Suppose we have some function f that takes as input a vector of real numbers and outputs a single real number. One simple such function is:\n",
    "```python\n",
    "def sum_of_squares(v):\n",
    "    \"\"\"computes the sum of squared elements in v\"\"\"\n",
    "    return sum(v_i ** 2 for v_i in v)\n",
    "```\n",
    "- We’ll frequently need to maximize (or minimize) such functions. \n",
    "    - That is, we need to find the input v that produces the largest (or smallest) possible value.\n",
    "- For functions like ours, the _gradient_ (if you remember your calculus, this is the vector of partial derivatives) gives the input direction in which the function most quickly increases.\n",
    "- Accordingly, one approach to maximizing a function is to pick a random starting point, compute the gradient, take a small step in the direction of the gradient (i.e., the direction that causes the function to increase the most), and repeat with the new starting point. \n",
    "- Similarly, you can try to minimize a function by taking small steps in the _opposite_ direction, as shown in Figure 8-1.\n",
    "\n",
    "![gradient descent minimum](neural_networks_images/gradient_descent_minimum.png)\n",
    "\n",
    "Note: “If a function has a unique global minimum, this procedure is likely to find it. If a function has multiple (local) minima, this procedure might “find” the wrong one of them, in which case you might re-run the procedure from a variety of starting points. If a function has no minimum, then it’s possible the procedure might go on forever.”\n",
    "\n",
    "#### Estimating Gradient\n",
    "If f is a function of one variable, its derivative at a point x measures how `f(x)` changes when we make a very small change to `x`. It is defined as the limit of the difference quotients:\n",
    "```python\n",
    "def difference_quotient(f, x, h):\n",
    "    return (f(x + h) - f(x)) / h\n",
    "\n",
    "# essentially calculation for gradient \n",
    "# of a straight line.\n",
    "```\n",
    "as `h` approaches zero.\n",
    "(Many a would-be calculus student has been stymied by the mathematical definition of limit. Here we’ll cheat and simply say that it means what you think it means.)\n",
    "\n",
    "The derivative is the slope of the tangent line at $(x, f(x))$, while the difference quotient is the slope of the not-quite-tangent line that runs through $(x+h, f(x+h))$. As $h$ gets smaller and smaller, the not-quite-tangent line gets closer and closer to the tangent line (Figure 8-2).\n",
    "\n",
    "Figure 8-2. Approximating a derivative with a difference quotient:\n",
    "![difference quotient](neural_networks_images/difference_quotient.png)\n",
    "\n",
    "Although we can’t take limits in Python, we can estimate derivatives by evaluating the difference quotient for a very small `e`. Figure 8-3 shows the results of one such estimation:\n",
    "```python\n",
    "derivative_estimate = partial(\n",
    "    difference_quotient, square, h=0.00001)\n",
    "\n",
    "# plot to show they're basically the same\n",
    "import matplotlib.pyplot as plt\n",
    "x = range(-10,10)\n",
    "plt.title(\"Actual Derivatives vs. Estimates\")\n",
    "plt.plot(x, map(derivative, x), \n",
    "        'rx', label='Actual')  # red  x\n",
    "plt.plot(x, map(derivative_estimate, x), \n",
    "        'b+', label='Estimate')  # blue +\n",
    "plt.legend(loc=9)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Figure 8-3. Goodness of difference quotient approximation:\n",
    "![derivatives: actual vs estimates](neural_networks_images/derivatives_actual_vs_estimates.png)\n",
    "\n",
    "\n",
    "When `f` is a function of many variables, it has multiple _partial derivatives_, each indicating how `f` changes when we make small changes in just one of the input variables.\n",
    "\n",
    "We calculate its `i`th partial derivative by treating it as a function of just its `i`th variable, holding the other variables fixed:\n",
    "```python\n",
    "def partial_difference_quotient(f, v, i, h):\n",
    "    \"\"\"compute the ith partial difference quotient of f at v\"\"\"\n",
    "    # add h to just the ith element of v\n",
    "    w = [v_j + (h if j == i else 0)\n",
    "         for j, v_j in enumerate(v)]\n",
    "\n",
    "    return (f(w) - f(v)) / h\n",
    "```\n",
    "after which we can estimate the gradient the same way:\n",
    "```python\n",
    "def estimate_gradient(f, v, h=0.00001):\n",
    "    return [partial_difference_quotient(f, v, i, h)\n",
    "            for i, _ in enumerate(v)]\n",
    "```\n",
    "\n",
    "Note: A major drawback to this “estimate using difference quotients” approach is that it’s computationally expensive. \n",
    "- If `v` has length `n`, `estimate_gradient` has to evaluate `f` on _2n_ different inputs. \n",
    "- If you’re repeatedly estimating gradients, you’re doing a whole lot of extra work.\n",
    "\n",
    "#### Using the Gradient\n",
    "It’s easy to see that the `sum_of_squares` function is smallest when its input `v` is a vector of zeroes. But imagine we didn’t know that. Let’s use gradients to find the minimum among all three-dimensional vectors. We’ll just pick a random starting point and then take tiny steps in the opposite direction of the gradient until we reach a point where the gradient is very small:\n",
    "\n",
    "```python\n",
    "def step(v, direction, step_size):\n",
    "    \"\"\"move step_size in the direction from v\"\"\"\n",
    "    return [v_i + step_size * direction_i\n",
    "            for v_i, direction_i in zip(v, direction)]\n",
    "\n",
    "def sum_of_squares_gradient(v):\n",
    "    return [2 * v_i for v_i in v]\n",
    "\n",
    "# pick a random starting point\n",
    "v = [random.randint(-10,10) for i in range(3)]\n",
    "\n",
    "tolerance = 0.0000001\n",
    "\n",
    "while True:\n",
    "    gradient = sum_of_squares_gradient(v)   # compute the gradient at v\n",
    "    next_v = step(v, gradient, -0.01)       # take a negative gradient step\n",
    "    if distance(next_v, v) < tolerance:     # stop if we're converging\n",
    "        break\n",
    "    v = next_v                              # continue if we're not\n",
    "```\n",
    "If you run this, you’ll find that it always ends up with a `v` that’s very close to `[0,0,0]`. The smaller you make the tolerance, the closer it will get.\n",
    "\n",
    "#### Choosing the Right Step Size\n",
    "Although the rationale for moving against the gradient is clear, how far to move is not. Indeed, choosing the right step size is more of an art than a science. Popular options include:\n",
    "- Using a fixed step size\n",
    "- Gradually shrinking the step size over time\n",
    "- At each step, choosing the step size that minimizes the value of the objective function\n",
    "\n",
    "The last sounds optimal but is, in practice, a costly computation. We can approximate it by trying a variety of step sizes and choosing the one that results in the smallest value of the objective function:\n",
    "```python\n",
    "step_sizes = [100, 10, 1, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "```\n",
    "It is possible that certain step sizes will result in invalid inputs for our function. So we’ll need to create a “safe apply” function that returns infinity (which should never be the minimum of anything) for invalid inputs:\n",
    "```python\n",
    "def safe(f):\n",
    "    \"\"\"return a new function that's the same as f,\n",
    "    except that it outputs infinity whenever f produces an error\"\"\"\n",
    "    def safe_f(*args, **kwargs):\n",
    "        try:\n",
    "            return f(*args, **kwargs)\n",
    "        except:\n",
    "            return float('inf')         # this means \"infinity\" in Python\n",
    "    return safe_f\n",
    "```\n",
    "\n",
    "#### Putting It All Together\n",
    "In the general case, we have some `target_fn` that we want to minimize, and we also have its `gradient_fn`. For example, the `target_fn` could represent the errors in a model as a function of its parameters, and we might want to find the parameters that make the errors as small as possible.\n",
    "Furthermore, let’s say we have (somehow) chosen a starting value for the parameters `theta_0`. Then we can implement gradient descent as:\n",
    "```python\n",
    "def minimize_batch(target_fn, gradient_fn, theta_0, tolerance=0.000001):\n",
    "  \"\"\"use gradient descent to find theta that minimizes target function\"\"\"\n",
    "\n",
    "  step_sizes = [100, 10, 1, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "\n",
    "  theta = theta_0                           # set theta to initial value\n",
    "  target_fn = safe(target_fn)               # safe version of target_fn\n",
    "  value = target_fn(theta)                  # value we're minimizing\n",
    "\n",
    "  while True:\n",
    "      gradient = gradient_fn(theta)\n",
    "      next_thetas = [step(theta, gradient, -step_size)\n",
    "                     for step_size in step_sizes]\n",
    "\n",
    "      # choose the one that minimizes the error function\n",
    "      next_theta = min(next_thetas, key=target_fn)\n",
    "      next_value = target_fn(next_theta)\n",
    "\n",
    "      # stop if we're \"converging\"\n",
    "      if abs(value - next_value) < tolerance:\n",
    "          return theta\n",
    "      else:\n",
    "          theta, value = next_theta, next_value\n",
    "```\n",
    "\n",
    "We called it `minimize_batch` because, for each gradient step, it looks at the entire data set (because `target_fn` returns the error on the whole data set). In the next section, we’ll see an alternative approach that only looks at one data point at a time.\n",
    "Sometimes we’ll instead want to _maximize_ a function, which we can do by minimizing its negative (which has a corresponding negative gradient):\n",
    "\n",
    "```pyhton\n",
    "def negate(f):\n",
    "  \"\"\"return a function that for any input x returns -f(x)\"\"\"\n",
    "  return lambda *args, **kwargs: -f(*args, **kwargs)\n",
    "\n",
    "def negate_all(f):\n",
    "  \"\"\"the same when f returns a list of numbers\"\"\"\n",
    "  return lambda *args, **kwargs: [-y for y in f(*args, **kwargs)]\n",
    "\n",
    "def maximize_batch(target_fn, gradient_fn, theta_0, tolerance=0.000001):\n",
    "  return minimize_batch(negate(target_fn),\n",
    "                        negate_all(gradient_fn),\n",
    "                        theta_0,\n",
    "                        tolerance)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent\n",
    "(From _Data Science from Scratch_ Chapter 8 on topic)\n",
    "\n",
    "As we mentioned before, often we’ll be using gradient descent to choose the parameters of a model in a way that minimizes some notion of error. Using the previous batch approach, each gradient step requires us to make a prediction and compute the gradient for the whole data set, which makes each step take a long time.\n",
    "\n",
    "Now, usually these error functions are _additive_, which means that the predictive error on the whole data set is simply the sum of the predictive errors for each data point.\n",
    "\n",
    "When this is the case, we can instead apply a technique called _stochastic gradient descent_, which computes the gradient (and takes a step) for only one point at a time. It cycles over our data repeatedly until it reaches a stopping point.\n",
    "\n",
    "During each cycle, we’ll want to iterate through our data in a random order:\n",
    "\n",
    "```python\n",
    "def in_random_order(data):\n",
    "    \"\"\"generator that returns the elements of data in random order\"\"\"\n",
    "    indexes = [i for i, _ in enumerate(data)]  # create a list of indexes\n",
    "    random.shuffle(indexes)                    # shuffle them\n",
    "    for i in indexes:                          # return the data in that order\n",
    "        yield data[i]\n",
    "```\n",
    "\n",
    "And we’ll want to take a gradient step for each data point. This approach leaves the possibility that we might circle around near a minimum forever, so whenever we stop getting improvements we’ll decrease the step size and eventually quit:\n",
    "\n",
    "```python\n",
    "def minimize_stochastic(target_fn, gradient_fn, x, y, theta_0, alpha_0=0.01):\n",
    "\n",
    "    data = zip(x, y)\n",
    "    theta = theta_0                             # initial guess\n",
    "    alpha = alpha_0                             # initial step size\n",
    "    min_theta, min_value = None, float(\"inf\")   # the minimum so far\n",
    "    iterations_with_no_improvement = 0\n",
    "\n",
    "    # if we ever go 100 iterations with no improvement, stop\n",
    "    while iterations_with_no_improvement < 100:\n",
    "        value = sum( target_fn(x_i, y_i, theta) for x_i, y_i in data )\n",
    "\n",
    "        if value < min_value:\n",
    "            # if we've found a new minimum, remember it\n",
    "            # and go back to the original step size\n",
    "            min_theta, min_value = theta, value\n",
    "            iterations_with_no_improvement = 0\n",
    "            alpha = alpha_0\n",
    "        else:\n",
    "            # otherwise we're not improving, so try shrinking the step size\n",
    "            iterations_with_no_improvement += 1\n",
    "            alpha *= 0.9\n",
    "\n",
    "        # and take a gradient step for each of the data points\n",
    "        for x_i, y_i in in_random_order(data):\n",
    "            gradient_i = gradient_fn(x_i, y_i, theta)\n",
    "            theta = vector_subtract(theta, scalar_multiply(alpha, gradient_i))\n",
    "\n",
    "    return min_theta\n",
    "```\n",
    "\n",
    "The stochastic version will typically be a lot faster than the batch version. Of course, we’ll want a version that maximizes as well:\n",
    "\n",
    "```python\n",
    "def maximize_stochastic(target_fn, gradient_fn, x, y, theta_0, alpha_0=0.01):\n",
    "  return minimize_stochastic(negate(target_fn),\n",
    "                             negate_all(gradient_fn),\n",
    "                             x, y, theta_0, alpha_0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mdlynch37/anaconda2/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "using the gradient\n",
      "minimum v [-2.611200379320695e-06, -3.65568053104897e-06, -2.0889603034565536e-06]\n",
      "minimum value 2.45461227155e-11\n",
      "\n",
      "using minimize_batch\n",
      "minimum v [0.0009969209968386874, 0.0006646139978924582, 0.0009969209968386874]\n",
      "minimum value 2.42941471407e-06\n",
      ">>> ^C\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mdlynch37/anaconda2/lib/python2.7/encodings/utf_8.py\", line 15, in decode\n",
      "    def decode(input, errors='strict'):\n",
      "KeyboardInterrupt\n",
      ">>> "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\n",
    "    '../../../../../coding/data-science-from-scratch-joel-grus/code/')\n",
    "# $python -i script.py\n",
    "!python2 -i ../../../../../coding/data-science-from-scratch-joel-grus/code/gradient_descent.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent or delta rule\n",
    "- When output _is not_ thresholded\n",
    "- The perceptron rule outlined above works fine when the data is linearly separable, but can fail to converge otherwise.\n",
    "- For more complicated data, we need a better training rule.\n",
    "- Using a sigmoid function to measure how much error we have, we can differentiate it to adjust the weights in order to minimize the unit's output error.\n",
    "- Most robust to data set that are not linearly separable\n",
    "    - converges to the limit of the local optimum\n",
    "- Relies on calculus to minimize the error, i.e. change the weights to push the error down\n",
    "    - 1/2 in equation does not affect outcome but it makes result of partial derivative calculation cleaner.\n",
    "\n",
    "![gradient descent calculation](neural_networks_images/gradient_descent_calc.png)\n",
    "\n",
    "#### Perceptron rule vs. gradient descent\n",
    "\n",
    "![perceptron rule vs gradient descent](neural_networks_images/perceptron_vs_gradient_d.png)\n",
    "\n",
    "### Sigmoid unit\n",
    "- Hack on the gradient descent equation that allows `y-hat` to be substituted and differentiated instead of `a`.\n",
    "- Uses a _sigmoid function_ to force this jump into a differentiable threshold\n",
    "- Calculus used to get to final equation below can be explored at [WolframMathWorld - Sigmoid Function](http://mathworld.wolfram.com/SigmoidFunction.html)\n",
    "\n",
    "![sigmoid for differentiable threshold](neural_networks_images/sigmoid.png)\n",
    "\n",
    "### Backpropogation trianing algorithm\n",
    "- \"A computationally beneficial organization of the chain rule.\"\n",
    "- Convenient method to compute derivatives with repsect to all the different weights in the network\n",
    "- Network learns through:\n",
    "    - Information flows from inputs to outputs\n",
    "    - Then, error information flows back from the outputs to the inputs\n",
    "- Could also be called _error back propogation_\n",
    "- Can be applied to units of another differentiable function\n",
    "- Error function, in this case some of least squares, can have multiple \"local\" optima / minima\n",
    "    - a single unit's error function will have one local optimum, bottom of one parabola, but globally multiple parabolas are combined from all units.\n",
    "\n",
    "![back propogation](neural_networks_images/back_propogation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing Weights, brief intro\n",
    "- Techniques to solve problem of multiple local optima, which will cause algorithm to get stuck in one minima even if it is not the global optima.\n",
    "- for image below: red bullet points are aspect that add to a model's complexity\n",
    "\n",
    "![opitmizing weights](neural_networks_images/optimizing_weights.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restriction Bias\n",
    "__definition__ of restriction bias:\n",
    "- Describes the _representational power_ of a particular data structure, e.g. of a network of neurons\n",
    "- Restricts the hypotheses that will be considered\n",
    "\n",
    "### Evaluating restriction bias\n",
    "- _perceptron unit:_ linear, only considering planes\n",
    "    - to _Networks of perceptrons:_ allows boolean functions like `XOR`\n",
    "    - to _Networks of units with sigmoids & other arbitrary functions:_ allows lots of layers and nodes that can become much more complex, not many restrictions at all\n",
    "- Neural networks can represent _any_ mapping of inputs to outputs, like:\n",
    "    - _boolean:_ with network of threshold-like units\n",
    "    - _continuous:_ as long as smooth curves, connected / no jumps\n",
    "        - using single hidden layer of nodes\n",
    "        - each node covers some portion of function\n",
    "        - nodes are then \"stitched together\" to give output\n",
    "    - _arbitrary:_ functions that aren't continuous\n",
    "        - requires two hidden layers\n",
    "        - with additional hidden layer, output can be stitched together even with gaps in the function.\n",
    "        \n",
    "### Overfitting\n",
    "- Danger of overfitting neural network can even represent noise in our training set\n",
    "- To solve this, restrict number of hidden nodes and layer in network\n",
    "    - Neural network can only capture as much of a function as its bounds allow\n",
    "    - i.e. the particular network architecture can have restrictions even though an unbounded neural network will not.\n",
    "- Other solutions are ones that are applied to other learners like:\n",
    "    - Cross validation to decide how many nodes per layer, how large weights can get before stopping. \n",
    "- Complexity of a neural network is not only in the nodes and layers, but also in its weights, i.e. how _much_ it is trained\n",
    "\n",
    "![restriction bias](neural_networks_images/restriction_bias.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preference Bias\n",
    "__definition__ of preference bias:\n",
    "- Characteristics that determine whether one subclass of algorithm would be selecteed over another.\n",
    "    - e.g. preferred decision trees are correct ones, one with top nodes having the most information gain, ones that aren't longer than necessary, etc.\n",
    "\n",
    "### Evaluating preference bias\n",
    "- For _neural networks with gradient descent:_\n",
    "    - prefers models with lower complexity (Occam's razor)\n",
    "        \n",
    "![preference bias](neural_networks_images/preference_bias.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Nets Mini-Project\n",
    "## 1. Build a Perceptron\n",
    "__question:__ What do you think the advantage of a perceptron is, compared with simply returning the dot product without a threshold?\n",
    "- (???) Guaranteed finite convergence for linearly separable data. Faster learning/optimization with near certain determination of nature of data (whether linearly separable or not)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-----------------------------------\n",
    "\n",
    "#\n",
    "#   In this exercise you will put the finishing \n",
    "#   touches on a perceptron class\n",
    "#\n",
    "#   Finish writing the activate() method by using \n",
    "#   numpy.dot and adding in the thresholded\n",
    "#   activation function\n",
    "\n",
    "from numpy import dot\n",
    "\n",
    "class Perceptron:\n",
    "\n",
    "    def activate(self,inputs):\n",
    "        '''Takes in @param inputs, a list of numbers.\n",
    "        @return the output of a threshold perceptron with\n",
    "        given weights, threshold, and inputs.\n",
    "        ''' \n",
    "\n",
    "        #YOUR CODE HERE\n",
    "\n",
    "        #TODO: calculate the strength with which the perceptron fires\n",
    "        w_x = dot(self.weights, inputs)        \n",
    "\n",
    "        #TODO: return 0 or 1 based on the threshold\n",
    "        result = 0 if w_x < self.threshold else 1\n",
    "        return result\n",
    "\n",
    "        \n",
    "        \n",
    "    def __init__(self,weights=None,threshold=None):\n",
    "        if weights is not None:\n",
    "            self.weights = weights\n",
    "        if threshold is not None:\n",
    "            self.threshold = threshold\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Perceptron Update Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#-----------------------------------\n",
    "\n",
    "#\n",
    "#   In this exercise we write a perceptron class\n",
    "#   which can update its weights\n",
    "#\n",
    "#   Your job is to finish the train method so that it implements the perceptron update rule\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class Perceptron:\n",
    "    \n",
    "    def activate(self,values):\n",
    "        '''Takes in @param values, @param weights lists of numbers\n",
    "        and @param threshold a single number.\n",
    "        @return the output of a threshold perceptron with\n",
    "        given weights and threshold, given values as inputs.\n",
    "        ''' \n",
    "               \n",
    "        #First calculate the strength with which the perceptron fires\n",
    "        strength = np.dot(values,self.weights)\n",
    "        \n",
    "        if strength>self.threshold:\n",
    "            result = 1\n",
    "        else:\n",
    "            result = 0\n",
    "            \n",
    "        return result\n",
    "\n",
    "    def update(self,values,train,eta=.1):\n",
    "        '''Takes in a 2D array @param values consisting of a LIST of inputs\n",
    "        and a 1D array @param train, consisting of a corresponding list of \n",
    "        expected outputs.\n",
    "        Updates internal weights according to the perceptron training rule\n",
    "        using these values and an optional learning rate, @param eta.\n",
    "        '''\n",
    "        #YOUR CODE HERE\n",
    "        #update self.weights based on the training data\n",
    "        \n",
    "        for x, y in zip(values, train):\n",
    "            y_pred = self.activate(x)\n",
    "            for i, x_i in enumerate(x):\n",
    "                self.weights[i] += (y - y_pred) * eta * x_i\n",
    "        \n",
    "\n",
    "    def __init__(self,weights=None,threshold=None):\n",
    "        if weights is not None:\n",
    "            self.weights = weights\n",
    "        if threshold is not None:\n",
    "            self.threshold = threshold\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build the XOR Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 xor 0: 0\n",
      "0 xor 1: 1\n",
      "1 xor 0: 1\n",
      "1 xor 1: 0\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#   In this exercise, you will create a network of perceptrons which\n",
    "#   represent the xor function use the same network structure you used\n",
    "#   in the previous quizzes.\n",
    "#\n",
    "#   You will need to do two things:\n",
    "#   First, create a network of perceptrons with the correct weights\n",
    "#   Second, define a procedure EvalNet() which takes in a list of \n",
    "#   inputs and ouputs the value of this network.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class Perceptron:\n",
    "\n",
    "    def evaluate(self,values):\n",
    "        '''Takes in @param values, @param weights lists of numbers\n",
    "        and @param threshold a single number.\n",
    "        @return the output of a threshold perceptron with\n",
    "        given weights and threshold, given values as inputs.\n",
    "        ''' \n",
    "               \n",
    "        #First calculate the strength with which the perceptron fires\n",
    "        strength = np.dot(values,self.weights)\n",
    "        \n",
    "        #Then evaluate the return value of the perceptron\n",
    "        if strength >= self.threshold:\n",
    "            result = 1\n",
    "        else:\n",
    "            result = 0\n",
    "\n",
    "        return result\n",
    "\n",
    "    def __init__(self,weights=None,threshold=None):\n",
    "        if weights is not None:\n",
    "            self.weights = weights\n",
    "        if threshold is not None:\n",
    "            self.threshold = threshold\n",
    "\n",
    "Network = [\n",
    "    #input layer, declare perceptrons here\n",
    "    # [OR_Perceptron, AND_Percaptron]\n",
    "    [ Perceptron([1, 1], 1), Perceptron([.5, .5], 1) ], \\\n",
    "    #output node, declare one perceptron here\n",
    "    # output = OR_Perceptron - 2*AND_Perceptron\n",
    "    [ Perceptron(weights=[1, -2], threshold=1) ]\n",
    "]\n",
    "\n",
    "def EvalNetwork(inputValues, Network):    \n",
    "    p_or = Network[0][0].evaluate(inputValues)\n",
    "    p_and = Network[0][1].evaluate(inputValues)\n",
    "    p_xor = Network[1][0].evaluate([p_or, p_and])\n",
    "    \n",
    "    OutputValues = p_xor\n",
    "    # Be sure your output values are single numbers\n",
    "    return OutputValues\n",
    "\n",
    "print '0 xor 0:', EvalNetwork([0,0], Network)\n",
    "print '0 xor 1:', EvalNetwork([0,1], Network)\n",
    "print '1 xor 0:', EvalNetwork([1,0], Network)\n",
    "print '1 xor 1:', EvalNetwork([1,1], Network)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Activation Function Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#   Python Neural Networks code originally \n",
    "#   by Szabo Roland and used by permission\n",
    "\n",
    "#   Modifications, comments, and exercise breakdowns \n",
    "#   by Mitchell Owen, (c) Udacity\n",
    "\n",
    "#   Retrieved originally from\n",
    "#   http://rolisz.ro/2013/04/18/neural-networks-in-python/\n",
    "\n",
    "#\tNeural Network Sandbox\n",
    "#\n",
    "#\tDefine an activation function activate(), \n",
    "#   which takes in a number and returns a number.\n",
    "#\tUsing test run you can see the performance of \n",
    "#   a neural network running with that activation function.\n",
    "#\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def activate(strength):\n",
    "    return np.power(strength,2)\n",
    "    \n",
    "def activation_derivative(activate, strength):\n",
    "    #numerically approximate\n",
    "    return (activate(strength+1e-5)-activate(strength-1e-5))/(2e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output through webapp:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
    "  'precision', 'predicted', average, warn_for)\n",
    "our weights [[ -9.39070541e-02  -1.04328949e-01   1.65772580e-01 ...,   3.95364078e-02\n",
    "   -8.79811120e-02   1.45551742e-01]\n",
    " [ -1.81965442e-01   2.23494036e-01   2.29270054e-01 ...,   5.60283791e-02\n",
    "    1.99415490e-01   2.41451736e-01]\n",
    " [  5.50110296e+01  -5.25212740e+01   1.74491734e+03 ...,   9.07396683e-01\n",
    "    4.48984591e+02  -8.64517579e+01]\n",
    " ..., \n",
    " [  1.73859117e-01   2.30827068e-01  -1.66113073e-01 ...,   2.34616668e-01\n",
    "    2.72151263e-02   2.35588898e-01]\n",
    " [  1.07146784e-01  -3.38694889e-02   4.71807362e-02 ...,   2.25425026e-01\n",
    "   -1.74156663e-01   1.57382086e-01]\n",
    " [  1.10227160e+02  -1.05335043e+02   3.48975870e+03 ...,   1.23151826e+00\n",
    "    8.98238455e+02  -1.72644011e+02]]\n",
    "\n",
    " are being modified with deltas [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
    "\n",
    " using the results matrix a: [[ 0.      0.      0.4375  0.9375  1.      1.      0.0625  0.      0.\n",
    "   0.5625  1.      1.      0.625   0.3125  0.      0.      0.      0.875\n",
    "   1.      1.      0.9375  0.      0.      0.      0.      0.6875  0.875\n",
    "   0.8125  1.      0.125   0.      0.      0.      0.      0.      0.375\n",
    "   1.      0.0625  0.      0.      0.      0.      0.      0.75    0.75    0.\n",
    "   0.      0.      0.      0.      0.375   1.      0.4375  0.      0.      0.\n",
    "   0.      0.      0.625   0.8125  0.      0.      0.      0.      1.    ]]\n",
    "(65, 16) (1, 16) (1, 65)\n",
    "our weights [[ -9.39070541e-02  -1.04328949e-01   1.65772580e-01 ...,   3.95364078e-02\n",
    "   -8.79811120e-02   1.45551742e-01]\n",
    " [ -1.81965442e-01   2.23494036e-01   2.29270054e-01 ...,   5.60283791e-02\n",
    "    1.99415490e-01   2.41451736e-01]\n",
    " [  5.50110296e+01  -5.25212740e+01   1.74491734e+03 ...,   9.07396683e-01\n",
    "    4.48984591e+02  -8.64517579e+01]\n",
    " ..., \n",
    " [  1.73859117e-01   2.30827068e-01  -1.66113073e-01 ...,   2.34616668e-01\n",
    "    2.72151263e-02   2.35588898e-01]\n",
    " [  1.07146784e-01  -3.38694889e-02   4.71807362e-02 ...,   2.25425026e-01\n",
    "   -1.74156663e-01   1.57382086e-01]\n",
    " [  1.10227160e+02  -1.05335043e+02   3.48975870e+03 ...,   1.23151826e+00\n",
    "    8.98238455e+02  -1.72644011e+02]]\n",
    "\n",
    " are being modified with deltas [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
    "\n",
    " using the results matrix a: [[ 0.      0.      0.4375  0.875   1.      0.5     0.      0.      0.      0.\n",
    "   0.875   0.875   1.      0.875   0.      0.      0.      0.      0.      0.\n",
    "   0.625   0.75    0.      0.      0.      0.      0.25    0.25    0.875\n",
    "   0.5625  0.125   0.      0.      0.4375  1.      1.      1.      1.\n",
    "   0.4375  0.      0.      0.375   0.75    1.      0.6875  0.0625  0.      0.\n",
    "   0.      0.      0.125   1.      0.1875  0.      0.      0.      0.      0.\n",
    "   0.375   0.8125  0.      0.      0.      0.      1.    ]]\n",
    "(65, 16) (1, 16) (1, 65)\n",
    "[[ 0 46  0  0  0  0  0  0  0  0]\n",
    " [ 0 53  0  0  0  0  0  0  0  0]\n",
    " [ 0 44  0  0  0  0  0  0  0  0]\n",
    " [ 0 37  0  0  0  0  0  0  0  0]\n",
    " [ 0 44  0  0  0  0  0  0  0  0]\n",
    " [ 0 39  0  0  0  0  0  0  0  0]\n",
    " [ 0 46  0  0  0  0  0  0  0  0]\n",
    " [ 0 40  0  0  0  0  0  0  0  0]\n",
    " [ 0 55  0  0  0  0  0  0  0  0]\n",
    " [ 0 46  0  0  0  0  0  0  0  0]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "          0       0.00      0.00      0.00        46\n",
    "          1       0.12      1.00      0.21        53\n",
    "          2       0.00      0.00      0.00        44\n",
    "          3       0.00      0.00      0.00        37\n",
    "          4       0.00      0.00      0.00        44\n",
    "          5       0.00      0.00      0.00        39\n",
    "          6       0.00      0.00      0.00        46\n",
    "          7       0.00      0.00      0.00        40\n",
    "          8       0.00      0.00      0.00        55\n",
    "          9       0.00      0.00      0.00        46\n",
    "\n",
    "avg / total       0.01      0.12      0.02       450\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sigmoid Programming Exercise\n",
    "\n",
    "Logistic used is sigmoid function: $ f(x) = \\frac{1}{1+e^{-x}} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attrerror \n",
      "0\n",
      "0.880797077978\n",
      "[2.990752195677017, -2.0184956086459658, 0.972256587031051]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#   As with the perceptron exercise, you will modify the\n",
    "#   last functions of this sigmoid unit class\n",
    "#\n",
    "#   There are two functions for you to finish:\n",
    "#   First, in activate(), write the sigmoid activation function\n",
    "#\n",
    "#   Second, in train(), write the gradient descent update rule\n",
    "#\n",
    "#   NOTE: the following exercises creating classes for functioning\n",
    "#   neural networks are HARD, and are not efficient implementations.\n",
    "#   Consider them an extra challenge, not a requirement!\n",
    "\n",
    "import numpy as np\n",
    "from math import exp\n",
    "from scipy.optimize import fmin\n",
    "\n",
    "class Sigmoid:\n",
    "        \n",
    "    def activate(self,values):\n",
    "        '''Takes in @param values, @param weights lists of numbers\n",
    "        and @param threshold a single number.\n",
    "        @return the output of a threshold perceptron with\n",
    "        given weights and threshold, given values as inputs.\n",
    "        ''' \n",
    "               \n",
    "        #First calculate the strength with which the perceptron fires\n",
    "        strength = self.strength(values)\n",
    "        self.last_input = strength\n",
    "        \n",
    "        #YOUR CODE HERE\n",
    "        #modify strength using the sigmoid activation function\n",
    "        \n",
    "        result = self.sigmoid(strength)\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    def strength(self,values):\n",
    "        strength = np.dot(values,self.weights)\n",
    "        return strength\n",
    "        \n",
    "        \n",
    "    def update(self,values,train,eta=.1):\n",
    "        '''\n",
    "        Updates the sigmoid unit with expected return\n",
    "        values @param train and learning rate @param eta\n",
    "        \n",
    "        By modifying the weights according to the gradient descent rule\n",
    "        '''\n",
    "        \n",
    "        #YOUR CODE HERE\n",
    "        #modify the perceptron training rule to a gradient descent\n",
    "        #training rule you will need to use the derivative of the\n",
    "        #logistic function evaluated at the last input value.\n",
    "        #Recall: d/dx logistic(x) = logistic(x)*(1-logistic(x))\n",
    "        # NOTE: last_input not needed\n",
    "        \n",
    "        y = train[0]\n",
    "        y_pred = self.activate(values)\n",
    "        for i in range(0,len(values)):\n",
    "            delta_w = (eta * (y-y_pred) * y_pred *\n",
    "                       (1 - y_pred) * values[i])\n",
    "            \n",
    "            self.weights[i] += delta_w\n",
    "\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        try:\n",
    "            return 1 / (1 + exp(-x))\n",
    "        except OverflowError:\n",
    "            return float('inf')\n",
    "\n",
    "    # returns the value of the derivative of our function\n",
    "    def derivative_sigmoid(self, x):\n",
    "        return self.sigmoid(x)*(1-self.sigmoid(x))\n",
    "\n",
    "    # we setup this function to pass into the fmin algorithm\n",
    "    def update_weight(self, direction,x,step):\n",
    "        x = x + direction*step\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "    def optimized_weight(self, x):\n",
    "\n",
    "        x = 2  # algorithm starts at x=2\n",
    "        precision = 0.0001\n",
    "\n",
    "        x_list, y_list = [x], [self.sigmoid(x)]\n",
    "\n",
    "\n",
    "        while True:\n",
    "            direction = -self.derivative_sigmoid(x)\n",
    "\n",
    "            # use scipy fmin function to find ideal step size.\n",
    "            step_size = fmin(self.update_weight, 0.1, (x,direction), \n",
    "                             disp = False)\n",
    "            x_new = x + (step_size * direction)\n",
    "\n",
    "            x_list.append(x_new)\n",
    "            y_list.append(self.sigmoid(x_new))\n",
    "\n",
    "            if abs(x_new - x) < precision:\n",
    "                return x_new\n",
    "            else:\n",
    "                x = x_new   \n",
    "\n",
    "    def __init__(self,weights=None):\n",
    "        if weights is not None:\n",
    "            self.weights = weights\n",
    "            \n",
    "            \n",
    "unit = Sigmoid(weights=[3,-2,1])\n",
    "unit.update([1,2,3],[0])\n",
    "print unit.weights\n",
    "#Expected: [2.99075, -2.0185, .97225]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
