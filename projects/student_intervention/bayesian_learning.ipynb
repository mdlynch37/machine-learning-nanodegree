{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Side notes\n",
    "_(code snippets, summaries, resources, etc.)_\n",
    "- Provides extra explanation: [_Bayesian Learning_ PDF by Udactiy](https://www.evernote.com/shard/s37/nl/1033921335/d62d0042-fbcb-4831-83d6-fe311e1bc6cd/) (Evernote)\n",
    "\n",
    "__definition:__ i.i.d. (independent, identically distributed)\n",
    "- A collection / sequence of random variables is _independent and identically distributed_ if\n",
    "    1. each random variable has the _same probability distribution_ as the others and \n",
    "    - are all _mutually independent_.\n",
    "\n",
    "__Notes on math used:__\n",
    "- Can switch $argmax$ to $argmin$ by multiplying equation by $-1$\n",
    "- Can simplify products into sums for $e^x$ with inverse $ln$ (and vice versa):\n",
    "    - Used to simplify Bayesian Learning equation to find best hypothesis\n",
    "    - Works with equations with $\\Sigma$ and $\\Pi$ (naturally)\n",
    "    - This works because:\n",
    "        - $ln(x)$ is the inverse of $e^x$\n",
    "        - and is also _monotonic_ (??) (as too is $e(x)$), which will not change the _argmax_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of topics covered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section uses Bayesian Learning and Classification (derived from Bayes' Rule) as the underlying theories that explain concepts and methods that we have already been using like the bias-variance tradeoff.\n",
    "\n",
    "![summary](bayesian_learning_images/summary.png)\n",
    "\n",
    "- Maximum a posteriori hypothesis h<sub>MAP</sub> is the maximum likelihood hypothesis h<sub>ML</sub> when the prior P(h) is uniform\n",
    "- Bayes' Optimal Classifier is where multiple hypotheses vote for most probable output for a particular data point\n",
    "    - On average, _we cannot do any better_ than using this method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes' Rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![naive bayes formula](naive_bayes_images/IMG_0316.jpg)</div>\n",
    "\n",
    "- P(E) (prior probability of evidence) acts as _normalizer for joint probability P(H, E)\n",
    "    - where P(E) is the sum of P(E|H) and P(E|H')\n",
    "    \n",
    "![simple diagram Bayes' rule in words](naive_bayes_images/5C7CC10B-2C1E-46E0-BABB-A131BCF3950E.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Testing for Cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cancer example question](naive_bayes_images/FA5ADE87-8BFC-434F-98D4-6D7122166298.png)\n",
    "\n",
    "Another way to phrase question:\n",
    "- Probability of correct positive = P(Pos|S)\n",
    "- Probability of correct negative = P(Pos'|S')\n",
    "\n",
    "![diagram of question](naive_bayes_images/90251E43-6F74-4A8D-AA00-7C27611418EA.png)</div>\n",
    "\n",
    "![answer calculation](naive_bayes_images/CC52E540-F6ED-4620-BFDA-9B35C7DD557B.png)\n",
    "\n",
    "__Detailed flow chart of Bayes' Rule for example:__\n",
    "\n",
    "![detailed flow diagram of Bayes' rule](naive_bayes_images/6E1DD6D8-10E4-49F7-ADE9-B68822ACAD32.png)\n",
    "\n",
    "- P(Pos, C) is joint probability, combines cancer hypothesis with the test result.\n",
    "- Normalizer in this case is P(Pos)\n",
    "\n",
    "__Note about result:__\n",
    "- Cancer test is not a good indicator of a patient having cancer\n",
    "    - to improve this, P(C) can be pushed up from 0.01 by using other symptoms to put patient in sub-population with higher P(C)\n",
    "    - Need to be later in the process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Testing for \"spleentitis\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![speentitis example](naive_bayes_images/speentitis_example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Learning Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![bayes' rule overview](bayesian_learning_images/bayes_rule_overview.png)\n",
    "\n",
    "Terms:\n",
    "- P(D|h) is probability of seeing data with given labels in a universe where _h_ happens to be true.\n",
    "- P(h|D) is...\n",
    "\n",
    "- Accepting features as given, Pr(D|h) measures probability of associated labels\n",
    "- Pr(D|h) represents type of accuracy measure\n",
    "- Pr(D) is not directly connected to the hypothesis\n",
    "- Pr(h), our _prior_ on a particular hypothesis drawn from the hypothesis space (_prior to seeing the data_)\n",
    "    - encapsulates our belief that one hypothesis is likely or unlikely compared to other hyotheses\n",
    "    - in fact, captures _domain knowledge_\n",
    "    - a hypothesis is more likely if, for example, points grouped together in k-NN get more similar labels than other hypotheses\n",
    "    - a hypothesis could be:\n",
    "        - a similarity metric in k-NN, or \n",
    "        - which features might be important relating to higher information gain in a decision tree, \n",
    "        - structure of a neural network, \n",
    "        - etc.\n",
    "\n",
    "![bayesian rule overview](bayesian_learning_images/bayesian_learning_algorithm.png)\n",
    "\n",
    "- To determine maximal hypothesis P(h|D) (hypothesis that is most likely given the data), do not need P(D) which is sometimes not available, so we use approximation of Pr(D|h) (the hypothesis that best matches the data)\n",
    "- P(h) can also be difficult to determine so we assume all hypothesis are equally likely, having a _uniform prior_\n",
    "    - which lets us ignore P(h) when determining _maximum likelihood hypothesis_ because \"we don't have a strong prior\"\n",
    "    - this h<sub>ML</sub>, or _maximum likely hypothesis_ is effectively the same as h<sub>MAP</sub>, or _maximum a posteriori hypothesis_, if there is not a strong prior\n",
    "- Hard part that remains is running through all possible hypotheses to determine _argmax of h_ P(h|D) (all possible hypotheses are effectively infinite)\n",
    "    - algorithm is not computationally practical, but conceptually useful\n",
    "    \n",
    "__This provides us with a \"gold standard\" with which to compare different hypotheses__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian learning in Action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some Terminology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Appended from [Version Spaces - Georgia Tech - Machine Learning](https://classroom.udacity.com/courses/ud675/lessons/383498973/concepts/3972687050923#) (from Udacity course on Supervised Learning):\n",
    "\n",
    "![version space terminology](bayesian_learning_images/version_space_terminology.png)\n",
    "\n",
    "Where\n",
    "- $S$ is training set consists of\n",
    "    - features / examples (a subset of all possbile inputs, $X$)\n",
    "    - labels / the _true class_ for all of those $x$'s\n",
    "- _Consistent learner_ is perfectly accurate for training data\n",
    "- _Version space__ is set of learners consistent with $S$\n",
    "- To test understanding, see [quiz](https://classroom.udacity.com/courses/ud675/lessons/383498973/concepts/6833586430923) that follows video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayesian Learning on data without noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From [Bayesian Learning in Action](https://classroom.udacity.com/nanodegrees/nd009/parts/0091345404/modules/5c2f3b47-b791-46a7-88eb-34a0753665e6/lessons/5462070314/concepts/4733385550923#) (Udacity video):\n",
    "\n",
    "![bayesian rule overview](bayesian_learning_images/bayesian_learning_in_practice.png)\n",
    "\n",
    "_Assumptions, explained:_\n",
    "1. $\\{<x_{i}, d_{i}>\\}$ training data, consisting of an input space and its labels\n",
    "    - labels can be classification data, etc.\n",
    "    - noise-free examples drawn from some underlying concept $c$\n",
    "    - $d_{i}$ = $c$ of $x_{i}$ (for all $x_{i}$)\n",
    "- $c \\in H$, i.e. true concept is in _hypothesis class_ or hypothesis space\n",
    "- uniform prior, i.e. no hypothesis in h is more likely than another.\n",
    "    - also called _uninformed prior_\n",
    "    \n",
    "_Generalized Bayes' Rule for Machine Learning, explained:_\n",
    "- P(h), since uniform, is just it's uniform part of P(all) = 1 of hypothesis class.\n",
    "- P(D|h) is probability of seeing $D$ in a universe where $h$ is true, or _the hypothesis that describes the data the best_. It will be:\n",
    "    - 1 if all labels match corresponding set of features, _h_ happens to be completely true (noise-free)\n",
    "    - 0 if not, i.e. any of the feature sets does not match its corresponding labels.\n",
    "    - will be between 0 and 1 if noise is factored into the calculation (see quiz below).\n",
    "- P(D) \n",
    "    - works because we have necessary terms\n",
    "    - works if hypotheses (all P(h<sub>$i$</sub>)) are mutually exclusive, which we always assume\n",
    "- P(h|D) is _the hypothesis that best fits the data_, which can be now be calculated with Bayes' rule.\n",
    "    - Result means: \"Given a bunch of data the probability of a particular hypothesis being correct is simply unifrom over all the hypotheses that in the version space, that is, are consistent with the data we see.\"\n",
    "    - P(h|D) = 0 if no hypothesis is consisted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayesian Learning on data with noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From 15-min course video [Return to Bayesian Learning](https://classroom.udacity.com/nanodegrees/nd009/parts/0091345404/modules/5c2f3b47-b791-46a7-88eb-34a0753665e6/lessons/5462070314/concepts/4733385600923#):\n",
    "\n",
    "![bayesian learning with noise 1](bayesian_learning_images/bayesian_learning_with_noise_1.png)\n",
    "\n",
    "Simplication (continued from above):\n",
    "\n",
    "![bayesian learning with noise 2](bayesian_learning_images/bayesian_learning_with_noise_2.png)\n",
    "\n",
    "(see definition for _i.i.d._ in Sidenotes section)\n",
    "\n",
    "Notes on math used for simplification above:\n",
    "- When maximizing a function (looking for _argmax_), we can simplify expression by ignoring values that will not effect the _argmax_, in this case, of _h_\n",
    "    - as done with $\\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}$ below\n",
    "- Can switch $argmax$ to $argmin$ by multiplying equation by $-1$\n",
    "- Can simplify products into sums for $e^x$ with inverse $ln$ (and vice versa):\n",
    "    - Used to simplify Bayesian Learning equation to find best hypothesis\n",
    "    - Works with equations with $\\Sigma$ and $\\Pi$ (naturally)\n",
    "    - This works because:\n",
    "        - $ln(x)$ is the inverse of $e^x$\n",
    "        - and is also _monotonic_ (??) (as too is $e(x)$), which will not change the _argmax_\n",
    "\n",
    "- _Beautiful_ result shows that minimizing SSE to maximize $h$ can be use to determine the most probable hypothesis given the training data\n",
    "    - Validates use of SSE in back propogation and other methods used on perceptrons with Bayesian Learning\n",
    "- Smart trick: Modeling noise as a Gaussian distribution\n",
    "    - Clever use of nature log\n",
    "- Assumptions:\n",
    "    - data has been corrupted by Gaussian noise\n",
    "        - which would mean error domain has zero mean\n",
    "    - we are modeling a deterministic function $f(x)$\n",
    "    - we know / can guess the hypothesis class (independent of other assumptions)\n",
    "\n",
    "NOTE: most likely doing something wrong if noise not Gaussian or function is not deterministic.\n",
    "- Example of $x$ as height and $d$ as weight:\n",
    "    - if error on weight but not height, these assumptions would be violated.\n",
    "    - Fortunately, linear regressions / lines are well-behaved in this case, if noise on $d$ is i.i.d. as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quiz: Noisy Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(shown as intro to _Bayesian Learning on data with noise_ section above)\n",
    "![quiz: noisy data](bayesian_learning_images/quiz_noisy_data.png)\n",
    "\n",
    "Notes on question:\n",
    "- ~$P(\\frac{1}{2^k})$ is a geometric sequence \n",
    "    - whose sum from 1 to infinity equals 1, \n",
    "    - and is therefore a _true probability distribution_\n",
    "- \"Noisy-data\" means some stochastic process is going on to distort the data.\n",
    "- important for error domain is that mean is zero (variance not)\n",
    "\n",
    "Notes on solution:\n",
    "- If any $d$ value is not a multiple of its $x$ value, then \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quiz: Best hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![quiz: best hypothesis](bayesian_learning_images/quiz_best_hypothesis.png)\n",
    "\n",
    "- Perhaps MOD function is best only because other options are so bad\n",
    "    - Check this by running a linear regression to determine best hypothesis\n",
    "- to assess the resulting regression (hypothesis): \n",
    "    - same described above\n",
    "    - calculate errors for each data point to give SSE value across data points\n",
    "- In actuality, data is weird enough that MOD performs best, even better than a regression function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimum Description Length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From course video [Minimum Description Length](https://classroom.udacity.com/nanodegrees/nd009/parts/0091345404/modules/5c2f3b47-b791-46a7-88eb-34a0753665e6/lessons/5462070314/concepts/4733385650923):\n",
    "\n",
    "![minimum description length 1](bayesian_learning_images/minimum_description_length_1.png)\n",
    "\n",
    "- Looking at the relationship of maximum a posteriori to information theory\n",
    "- Information theory is usually entropy, \"sum of P log P\" (??)\n",
    "- Entropy concept comes straight out of Information Theory\n",
    "- \"We want to somehow minimize two terms that can be described as lengths\"\n",
    "    - \"length of hypothesis given the hypothesis ( because P(D|h) ~ P(h|D) ) and the length of the hypothesis\"\n",
    "- \"length of a hypothesis\" means _the number of bits needed to represent a hypothsis_\n",
    "    - which is why we us $lg$ (log base 2)\n",
    "\n",
    "Continued from above (after quiz on choosing smaller DT):\n",
    "\n",
    "![minimum description length 2](bayesian_learning_images/minimum_description_length_2.png)\n",
    "\n",
    "__length(h)__:\n",
    "- Smaller Decision Tree (fewer nodes, less depth, etc.) mean smaller hypothesis length or _size_\n",
    "- Can think about our bias for shorter decision tree as the prior P(h)\n",
    "- Kind of a Bayesian argument for Occam's Razor, which is often the rationale for pruning DTs\n",
    "\n",
    "__length(D|h):__\n",
    "- i.e. the length of the data given a particular hypothesis\n",
    "- Can be interpretted as:\n",
    "    - If hypothesis matches the data perfectly, then data in term have no relevance\n",
    "    - Otherwise, D would be represented by the error of the hypothesis on the data\n",
    "    - If hypothesis does not match the data at all, then D would contain all the correct answers.\n",
    "    - Captures the notion of fit of a particular hypothesis\n",
    "   \n",
    "__Therefore length(h)+ length(D|h):__ \n",
    "- maximum a posteriori hypothesis would be a one that:\n",
    "    - is the simplest hypothesis, $-lgP(h)$ or length(h)\n",
    "    - that minimizes the error, $-lgP(D|h)$ or length(D|h)\n",
    "- Represents a fundamental tradeoff in ML\n",
    "- Called _minimum description_\n",
    "- Applies to Neural Nets as well\n",
    "    - Minimizing weights to minimize length / size of hypothesis for nodes prevents overfitting\n",
    "- Another validation of Occum's Razor and tradeoffs in ML from Bayesian Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With quiz to introduce Bayesian Classification:\n",
    "\n",
    "![bayesian classification](bayesian_learning_images/bayesian_classification.png)\n",
    "\n",
    "- Bayesian Classification _is not the same as_ Bayesian Learning in that\n",
    "    - Bayesian Classification looks as most probable _label_ (or $v$ for value) for a particular data point instead of most probable _hypothesis_ for training data\n",
    "- Student can derive / simplify similar equation to Bayesian Learning equation with similar method used above.\n",
    "- Determining the most probable value is what we care about, assessing hypotheses' porbabilities is just the means to that end"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
