{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Side notes \n",
    "_(code snippets, summaries, resources, etc.)_\n",
    "- Exact videos from Lesson 6 in Intro to Machine Learning.\n",
    "- [Notes from lesson](https://www.evernote.com/shard/s37/nl/1033921335/93cde936-387d-49cb-9cca-1352ad78d821/) copied from Evernote, straight from html to markdown auto-conversion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>**Continuous vs. Discrete Output for Supervised Learning**</div>\n",
    "\n",
    "*   Prior examples (slow, fast, etc.) used discrete output with binary labelling. \n",
    "\n",
    "<div>Examples of continuous output:</div>\n",
    "\n",
    "*   _Ordered on scale_\n",
    "*   Age (encoded as number of seconds after they are born)\n",
    "*   Income\n",
    "*   Speed in mph (as opposed to fast/slow binary labels)\n",
    "\n",
    "<div>Examples of discrete output:</div>\n",
    "\n",
    "*   _Order not important_\n",
    "*   Weather (rainy or sunny options only given)\n",
    "*   Person wrote email, indexed at 1 to 100.\n",
    "*   Phone number (with input of features of a person)\n",
    "    *   No real relationship between numbers next to each other in an ordered scale\n",
    "\n",
    "<div>\n",
    "\n",
    "* * *\n",
    "\n",
    "</div>\n",
    "\n",
    "<div>**<span style=\"font-size: 18px;\">[1.1\\. Generalized Linear Models](http://scikit-learn.org/stable/modules/linear_model.html)</span>**</div>\n",
    "\n",
    "<div>[<span style=\"font: 14.0px Courier\">sklearn.linear_model</span>.LinearRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression)</div>\n",
    "\n",
    "<div>![](regressions_images/C63F564A-E377-4927-8B8D-3771B5C5A9BE.png)</div>\n",
    "\n",
    "<div>OR use: <span style=\"font: 14.0px Courier\">from sklearn.linear_model import LinearRegression</span></div>\n",
    "\n",
    "*   <span style=\"font: 14.0px Courier\">clf.predict([])</span>  takes a list as the argument\n",
    "\n",
    "<div>![](regressions_images/BAD49392-0978-4682-AA98-4DCD7AA2BFDB.png)</div>\n",
    "\n",
    "<div>**Regression errors and analysis**</div>\n",
    "\n",
    "*   Regressions have different kinds of errors than do classifiers\n",
    "\n",
    "<div>Error = actual net worth – predicted net worth (negative values can be result too)</div>\n",
    "\n",
    "<div>![](regressions_images/2444E03C-9323-4443-8141-71E87428EB00.png)</div>\n",
    "\n",
    "<div>The best regression will <u>Minimizing the Sum of Squared Errors</u></div>\n",
    "\n",
    "<div>![](regressions_images/314E2C96-B002-46C5-8184-DFF05E42FE68.png)</div>\n",
    "\n",
    "<div>Algorithms that do this:</div>\n",
    "\n",
    "*   Ordinary Least Squares (OLS), in sklearn\n",
    "*   Gradient Descent (not important to get into)\n",
    "\n",
    "<div><u>Why error squared?</u></div>\n",
    "\n",
    "*   multiple lines can minimize ![](regressions_images/8D380AF8-5DBD-4B20-A145-53490C4A1CB4.png).\n",
    "    *   good example is where there is an equal number of points on either side of two lines.\n",
    "    *   both can have the same ![](regressions_images/8D380AF8-5DBD-4B20-A145-53490C4A1CB4.png) even though one is closer to the middle of the points.\n",
    "*   ![](regressions_images/706AE609-1EDE-4F35-9752-E1852E14BD12.png) will avoid that fundamental ambiguity) and only return one lines in the example above\n",
    "\n",
    "<div>Also, much easier implementation of the algorithm computationally</div>\n",
    "\n",
    "<div><u>Problems with SSE</u></div>\n",
    "\n",
    "<div>As you add more data, SSE increases, so not good for data sets of differing sizes.</div>\n",
    "\n",
    "<div>![](regressions_images/95A55742-807B-4088-AE78-F1D8567E6CA4.png)</div>\n",
    "\n",
    "<div><u>r squared of a regression</u></div>\n",
    "\n",
    "<div>r^2 = “How much of my change in the output (y) is explained by the change in the my input (x)\"</div>\n",
    "\n",
    "*   note: x is the explanatory variable, or independent variable depending on its relationship to dependent/response variable (from [statisticshowto page](http://www.statisticshowto.com/explanatory-variable/) on vars)\n",
    "*   Udacity referred to x and an input variable\n",
    "\n",
    "<div>![](regressions_images/C11FB950-544D-476F-A6E4-4BE3FA09B025.png)</div>\n",
    "\n",
    "*   pro: r^2 is independent of number of data points\n",
    "\n",
    "<div>Use:<span style=\"font-family: Courier;\"> </span><span style=\"font: 14.0px Courier\">reg.score</span>(X, y, sample_weight=None) after regression has been fit.</div>\n",
    "\n",
    "<div>Can be an art interpreting r^2:</div>\n",
    "\n",
    "*   More features can push up r^2\n",
    "*   With smaller datasets (like in political science), lower r^2 values are expected and can be relevant.\n",
    "\n",
    "<div>![](regressions_images/86AB7FBF-C7AF-4F9F-8438-E27063B46951.png)</div>\n",
    "\n",
    "<div>\n",
    "\n",
    "* * *\n",
    "\n",
    "</div>\n",
    "\n",
    "<div><span style=\"font-size: 18px;\">**Classification vs Regression**</span></div>\n",
    "\n",
    "<div>We can think of regression _as a different type of supervised learning_</div>\n",
    "\n",
    "<div>![](regressions_images/737B84D2-20D0-480F-848B-05B0D89FC3E6.png)</div>\n",
    "\n",
    "<div>\n",
    "\n",
    "* * *\n",
    "\n",
    "</div>\n",
    "\n",
    "<div><span style=\"font-size: 18px;\">**Multivariate Regression Quizes**</span></div>\n",
    "\n",
    "*   Multiple input variables\n",
    "\n",
    "<div>Hint: work horizontally, then vertically and the other numbers will fall into place.</div>\n",
    "\n",
    "<div>Piece of software will do this for us (example very simple, unrealistic)</div>\n",
    "\n",
    "<div>![](regressions_images/8EE0A6EF-BF9D-4E33-A950-825E381D4AC3.png)</div>\n",
    "\n",
    "<div>![](regressions_images/01DD0CA3-FDF6-4A67-8AA9-DF07FAA96166.png)</div>\n",
    "\n",
    "<div>\n",
    "\n",
    "* * *\n",
    "\n",
    "</div>\n",
    "\n",
    "<div><span style=\"font-size: 18px;\">**Mini-project: Regression**</span></div>\n",
    "\n",
    "<div>In this project, you will use regression to predict financial data for Enron employees and associates. Once you know some financial data about an employee, like their salary, what would you predict for the size of their bonus?</div>\n",
    "\n",
    "<div>from finance_regression.py:</div>\n",
    "\n",
    "<div>![](regressions_images/DD9C29B7-F9A6-417E-B6A9-338DB74096A2.png)</div>\n",
    "\n",
    "<div><u>Regression with training data (correct answer for quiz):</u></div>\n",
    "\n",
    "<div>NOTE: Always run regression on test data not training data</div>\n",
    "\n",
    "<div>-1.48 is a very bad score, 0.0455 is not bad, but testing on the wrong data.</div>\n",
    "\n",
    "<div>![](regressions_images/3F11C4CA-AB2D-4877-86F5-69997601CBB2.png)</div>\n",
    "\n",
    "<div>![](regressions_images/E4F497D3-0AA6-4F58-9C7E-B36EE5DC2D35.png)</div>\n",
    "\n",
    "<div>**Regressing Bonus Against Long-term Incentive**</div>\n",
    "\n",
    "<div>There are lots of finance features available, some of which might be more powerful than others in terms of predicting a person’s bonus. For example, suppose you thought about the data a bit and guess that the “long_term_incentive” feature, which is supposed to reward employees for contributing to the long-term health of the company, might be more closely related to a person’s bonus than their salary is.</div>\n",
    "\n",
    "<div>A way to confirm that you’re right in this hypothesis is to regress the bonus against the long term incentive, and see if the regression score is significantly higher than regressing the bonus against the salary. Perform the regression of bonus against long term incentive--what’s the score on the test data?</div>\n",
    "\n",
    "<div><u>Results:</u></div>\n",
    "\n",
    "<div>Long-term bonus is a much better predictor/input feature of an employee’s bonus</div>\n",
    "\n",
    "<div>![](regressions_images/BA246D3E-986C-485E-9FB7-7D383C3F40DA.png)</div>\n",
    "\n",
    "<div>![](regressions_images/F299EC50-6EF9-482D-9461-8A30CADD0DD4.png)</div>\n",
    "\n",
    "<div>\n",
    "\n",
    "* * *\n",
    "\n",
    "</div>\n",
    "\n",
    "<div><span style=\"font-size: 18px;\">**Sneak Peek: Outliers Break Regressions**</span></div>\n",
    "\n",
    "<div><u>Added regression is on test data which does not include high-salaried, low-bonused outlier</u></div>\n",
    "\n",
    "<div>![](regressions_images/B7152A01-65D3-4759-B73A-F84209DF13DB.png)</div>\n",
    "\n",
    "<div>![](regressions_images/CC953D80-3258-4268-97DE-15A9904B8681.png)</div>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
