{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Side notes \n",
    "_(code snippets, summaries, resources, etc.)_\n",
    "\n",
    "__Further Reading:__\n",
    "- [Kaggle project](https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-1-for-beginners-bag-of-words)`\n",
    "    - If you're interested in the details of language processing, you might start with this project, which introduces a more detailed and standard approach to text processing very different from what we cover here.\n",
    "\n",
    "__Python code snippets:__\n",
    "- Strip punctuation from String (from good [StackOverflow](http://stackoverflow.com/questions/265960/best-way-to-strip-punctuation-from-a-string-in-python) answer)\n",
    "```python\n",
    "import string\n",
    "s = \"string. With. Punctuation?\" # Sample string \n",
    "out = s.translate(string.maketrans(\"\",\"\"), string.punctuation)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-Project: Bayes with Natural Language Processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bad Handwriting Exposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Bad Handwriting Exposition](mini-project_bayes_natural_language_processing_images/exposition.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming the above text is representative, calculate the following probabilities:\n",
    "1. Finding the word \"you\" after \"if\":\n",
    "    - $P(you|if) = \\frac{P(if|you)P(you)}{P(if)}$\n",
    "    - $P(you) = P(if) = \\frac{1}{21}$\n",
    "    - $\\therefore$ $P(you|if) = P(if|you)$\n",
    "    - $\\implies$ $P(you|if) = 1$\n",
    "- That a randomly selected word is \"you\":\n",
    "    - $P(you) = \\frac{1}{22} = 0.0454546$\n",
    "- That a randomly selected word is \"if\":\n",
    "    - $P(you) = \\frac{1}{22} = 0.0454546$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import string\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of all words:  22\n",
      "no. of unique words:  21\n",
      "no. most common words:  [('and', 2), ('there,', 1)]\n",
      "\n",
      "no. of you's 1\n",
      "no. of if's 1\n"
     ]
    }
   ],
   "source": [
    "sentence = '''\n",
    "So if you could just go ahead and pack \n",
    "up your stuff and move it down there, \n",
    "that would be terrific, OK?\n",
    "'''\n",
    "\n",
    "s = \"string. With. Punctuation?\" # Sample string \n",
    "out = s.translate(string.maketrans(\"\",\"\"), string.punctuation)\n",
    "words = sentence.split(' ')\n",
    "\n",
    "cnt = Counter()\n",
    "for word in words:\n",
    "    cnt[word] += 1\n",
    "print 'no. of all words: ', len(words)\n",
    "print 'no. of unique words: ', len(cnt)\n",
    "print 'no. most common words: ', cnt.most_common(2)\n",
    "print\n",
    "print 'no. of you\\'s', cnt['you']\n",
    "print 'no. of if\\'s', cnt['if']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "be\n",
      "for randomly chosen word: ' be ':\n",
      "\n",
      "3\n",
      "{'terrific': 1, 'great': 1, 'here': 1}\n"
     ]
    }
   ],
   "source": [
    "# not split into more readable lines\n",
    "original_sample_memo = '''\n",
    "Milt, we're gonna need to go ahead and move you downstairs into storage B. We have some new people coming in, and we need all the space we can get. So if you could just go ahead and pack up your stuff and move it down there, that would be terrific, OK?\n",
    "Oh, and remember: next Friday... is Hawaiian shirt day. So, you know, if you want to, go ahead and wear a Hawaiian shirt and jeans.\n",
    "Oh, oh, and I almost forgot. Ahh, I'm also gonna need you to go ahead and come in on Sunday, too...\n",
    "Hello Peter, whats happening? Ummm, I'm gonna need you to go ahead and come in tomorrow. So if you could be here around 9 that would be great, mmmk... oh oh! and I almost forgot ahh, I'm also gonna need you to go ahead and come in on Sunday too, kay. We ahh lost some people this week and ah, we sorta need to play catch up.\n",
    "'''\n",
    "\n",
    "sample_memo = '''\n",
    "Milt, we're gonna need to go ahead and move \n",
    "you downstairs into storage B. We have some \n",
    "new people coming in, and we need all the space \n",
    "we can get. So if you could just go ahead and \n",
    "pack up your stuff and move it down there, that \n",
    "would be terrific, OK?\n",
    "\n",
    "Oh, and remember: next Friday... is Hawaiian \n",
    "shirt day. So, you know, if you want to, go ahead \n",
    "and wear a Hawaiian shirt and jeans.\n",
    "Oh, oh, and I almost forgot. Ahh, I'm also gonna \n",
    "need you to go ahead and come in on Sunday, too...\n",
    "\n",
    "Hello Peter, whats happening? Ummm, I'm gonna need \n",
    "you to go ahead and come in tomorrow. So if you \n",
    "could be here around 9 that would be great, mmmk... \n",
    "oh oh! and I almost forgot ahh, I'm also gonna need \n",
    "you to go ahead and come in on Sunday too, kay. We \n",
    "ahh lost some people this week and ah, we sorta need \n",
    "to play catch up.\n",
    "'''\n",
    "\n",
    "#\n",
    "#   Maximum Likelihood Hypothesis\n",
    "#\n",
    "#\n",
    "#   In this quiz we will find the maximum likelihood \n",
    "#   word based on the preceding word.\n",
    "#\n",
    "#   Fill in the NextWordProbability procedure so that \n",
    "#   it takes in sample text and a word,\n",
    "#   and returns a dictionary with keys the set of \n",
    "#   words that come after, whose values are\n",
    "#   the number of times the key comes after that word.\n",
    "#   \n",
    "#   Just use .split() to split the sample_memo text \n",
    "#   into words separated by spaces.\n",
    "\n",
    "from collections import Counter\n",
    "import string\n",
    "from random import randint\n",
    "\n",
    "def SampleTextPreprocessing(sampletext):\n",
    "    #!! Issue that punctuation within word like 'we're' is taken out too\n",
    "    # this can cause problems because \"we're\" will be confused with \"were\"\n",
    "    s = sampletext\n",
    "    s = s.replace('\\n','')\n",
    "    s = s.translate(string.maketrans(\"\",\"\"), string.punctuation)\n",
    "    words = s.split(' ')\n",
    "\n",
    "    return words\n",
    "\n",
    "def NextWordProbability(sampletext, word):\n",
    "    words = SampleTextPreprocessing(sampletext)\n",
    "    words\n",
    "    next_words = [words[i+1] for i, w in enumerate(words[:-1]) if w == word]\n",
    "\n",
    "    cnt = Counter()\n",
    "    for w in next_words:\n",
    "        cnt[w] += 1\n",
    "    \n",
    "    return dict(cnt)\n",
    "\n",
    "# Test code\n",
    "num_words = len(words)\n",
    "i = randint(0, num_words-1)\n",
    "random_word = words[i]\n",
    "print random_word\n",
    "print \"for randomly chosen word: \\'\", random_word, \"\\':\"  # ??why spaces in ' word '?\n",
    "print\n",
    "print len(NextWordProbability(sample_memo, random_word))\n",
    "print NextWordProbability(sample_memo, random_word)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Disclaimer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous exercise, you may have thought of some ways we might want to clean up the text available to us.\n",
    "\n",
    "For example, we would certainly want to remove punctuation, and generally want to make all strings lowercase for consistency. In most language processing tasks we will have a much larger corpus of data, and will want to remove certain features.\n",
    "\n",
    "Overall, just keep in mind that this mini-project is about Bayesian probability. If you're interested in the details of language processing, you might start with this [Kaggle project](https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-1-for-beginners-bag-of-words), which introduces a more detailed and standard approach to text processing very different from what we cover here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal Classifier Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method: Made tree diagram and add up probabilities for each word.\n",
    "\n",
    "1. What word should you predict in the second blank?\n",
    "    - Job\n",
    "- With what probability?\n",
    "    - 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal Classifier Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "come\n",
      "go\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------\n",
    "\n",
    "#\n",
    "#   Bayes Optimal Classifier\n",
    "#\n",
    "#   In this quiz we will compute the optimal label \n",
    "#   for a second missing word in a row\n",
    "#   based on the possible words that could be in the \n",
    "#   first blank\n",
    "#\n",
    "#   Finish the procedurce, LaterWords(), below\n",
    "#\n",
    "#   You may want to import your code from the previous \n",
    "#   programming exercise!\n",
    "#\n",
    "\n",
    "original_sample_memo = '''\n",
    "Milt, we're gonna need to go ahead and move you downstairs into storage B. We have some new people coming in, and we need all the space we can get. So if you could just go ahead and pack up your stuff and move it down there, that would be terrific, OK?\n",
    "Oh, and remember: next Friday... is Hawaiian shirt day. So, you know, if you want to, go ahead and wear a Hawaiian shirt and jeans.\n",
    "Oh, oh, and I almost forgot. Ahh, I'm also gonna need you to go ahead and come in on Sunday, too...\n",
    "Hello Peter, whats happening? Ummm, I'm gonna need you to go ahead and come in tomorrow. So if you could be here around 9 that would be great, mmmk... oh oh! and I almost forgot ahh, I'm also gonna need you to go ahead and come in on Sunday too, kay. We ahh lost some people this week and ah, we sorta need to play catch up.\n",
    "'''\n",
    "\n",
    "sample_memo = '''\n",
    "Milt, we're gonna need to go ahead and move \n",
    "you downstairs into storage B. We have some \n",
    "new people coming in, and we need all the space \n",
    "we can get. So if you could just go ahead and \n",
    "pack up your stuff and move it down there, that \n",
    "would be terrific, OK?\n",
    "\n",
    "Oh, and remember: next Friday... is Hawaiian \n",
    "shirt day. So, you know, if you want to, go ahead \n",
    "and wear a Hawaiian shirt and jeans.\n",
    "Oh, oh, and I almost forgot. Ahh, I'm also gonna \n",
    "need you to go ahead and come in on Sunday, too...\n",
    "\n",
    "Hello Peter, whats happening? Ummm, I'm gonna need \n",
    "you to go ahead and come in tomorrow. So if you \n",
    "could be here around 9 that would be great, mmmk... \n",
    "oh oh! and I almost forgot ahh, I'm also gonna need \n",
    "you to go ahead and come in on Sunday too, kay. We \n",
    "ahh lost some people this week and ah, we sorta need \n",
    "to play catch up.\n",
    "'''\n",
    "\n",
    "corrupted_memo = '''\n",
    "Yeah, I'm gonna --- you to go ahead --- --- complain \n",
    "about this. Oh, and if you could --- --- and sit at \n",
    "the kids' table, that'd be --- \n",
    "'''\n",
    "\n",
    "data_list = sample_memo.strip().split()\n",
    "\n",
    "words_to_guess = [\"ahead\",\"could\"]\n",
    "\n",
    "\n",
    "# conditional probabily tree used for later questions / debugging\n",
    "cond_prob_tree = defaultdict(dict)\n",
    "\n",
    "def NextWordProbabilityCalculated(sample, word):\n",
    "    next_words = NextWordProbability(sample, word)\n",
    "    n = sum(next_words.values())\n",
    "    return {word: count/(n*1.) \n",
    "            for word, count in next_words.iteritems()}\n",
    "\n",
    "def LaterWords(sample,word,distance):\n",
    "    '''\n",
    "    @param sample: a sample of text to draw from\n",
    "    @param word: a word occuring before a corrupted sequence\n",
    "    @param distance: how many words later to estimate \n",
    "        (i.e. 1 for the next word, 2 for the word after that)\n",
    "    @returns: a single word which is the most likely possibility\n",
    "    '''\n",
    "    \n",
    "    # TODO: Given a word, collect the relative probabilities \n",
    "    # of possible following words\n",
    "    # from @sample. You may want to import your code from the \n",
    "    # maximum likelihood exercise.\n",
    "    \n",
    "    # TODO: Repeat the above process--for each distance beyond 1, \n",
    "    # evaluate the words that\n",
    "    # might come after each word, and combine them weighting by \n",
    "    # relative probability\n",
    "    # into an estimate of what might appear next.\n",
    "    \n",
    "    #if distance == 0:\n",
    "        \n",
    "    next_probs = NextWordProbabilityCalculated(sample, word)\n",
    "    \n",
    "    if distance == 1:\n",
    "        return max(next_probs.iterkeys(), \n",
    "                   key=(lambda key: next_probs[key]))\n",
    "    \n",
    "    prev_probs = next_probs\n",
    "    \n",
    "    cond_probs = defaultdict(lambda : 0)\n",
    "    \n",
    "    global cond_prob_tree\n",
    "    \n",
    "    # run through each possiblity for first blank\n",
    "    for prev_word, prev_prob in prev_probs.iteritems():\n",
    "        next_probs = NextWordProbabilityCalculated(sample, prev_word)\n",
    "        \n",
    "        for next_word, next_prob in next_probs.iteritems():\n",
    "            cond_prob_tree[prev_word][next_word] = prev_prob * next_prob\n",
    "            cond_probs[next_word] += prev_prob * next_prob\n",
    "    return max(cond_probs.iterkeys(),\n",
    "               key=(lambda key: cond_probs[key]))\n",
    "\n",
    "\n",
    "for word in words_to_guess:\n",
    "    print LaterWords(sample_memo, word, 2)\n",
    "    \n",
    "### NOTE: result for 'could' differs from quiz which gives 'in'\n",
    "### Not sure what's going on but quiz says output for my code is correct\n",
    "### giving 'come' and 'go'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which Words Meditation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What set of words in a memo do you think could help predict what a missing word might be?\n",
    "    - The words in the sample text that come after the word preceding the missing word in the corrupted text.\n",
    "\n",
    "2. What are some advantages and disadvantages of using fewer possible influences in prediction?\n",
    "    - I will interpret more possible influences as words farther back than just one preceeding word for each instance in the sample text.\n",
    "    - Advantages: Given enough training data, looking at the string n-number of words back from the word preceding the missing text would give higher accuracy. This is because phrases would be taken into account, resulting in richer data for a more likely prediction.\n",
    "    - Disadvantages: If there is not enough data, the drastic reduction of possible words for a missing word would cause overfitting. Data would be richer, but would not have enough of it to generalize to unseen text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint Distribution Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wanted to measure the joint probability distribution of a missing word given its position relative to every other word in the document, how many probabilites would you need to measure? Say the document is $N$ words long.\n",
    "- $N^2$ number of probabilities\n",
    "- \"When we only measured the likelihood of the word before, we had only N computations. Including regular expressions, the maximum amount of information we could use is super-exponential in the vocabulary size!\"\n",
    "- My attempt at an explanation:\n",
    "    - Assuming each word occurs independently for the others (Naive Bayes), the Conditional Independence Rule would allow us to ignore all words in the prior probability\n",
    "    - i.e. $P(x|y) = P(x|y_{1}, y_{2}, y_{n})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain Knowledge Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the corpus of text we have from our boss, we might like to identify some things he often says, and use that knowledge to make better predictions.\n",
    "\n",
    "What are some statements you see arising multiple times? (see sample_memo above)\n",
    "- \"gonna need to go ahead and\",\n",
    "- \"gonna need you to go ahead and\",\n",
    "- \"so if you could â€¦ that would be (great, ok)\",\n",
    "- \"oh, and I almost forgot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165\n",
      "127\n",
      "36\n",
      "gonna just go         0.5\n",
      "need just go          0.5\n",
      "to go ahead           0.833333333333\n",
      "go ahead and          1.0\n",
      "ahead ahead and       1.0\n",
      "and ahead and         1.0\n",
      "move ahead and        1.0\n",
      "you ahead and         1.0\n",
      "downstairs into storage  1.0\n",
      "into into storage     1.0\n",
      "storage into storage  1.0\n",
      "B. into storage       1.0\n",
      "We into storage       1.0\n",
      "have B We             1.0\n",
      "some B We             1.0\n",
      "new B We              1.0\n",
      "people B We           1.0\n",
      "coming into storage   1.0\n",
      "in, into storage      1.0\n",
      "and into storage      1.0\n",
      "we into storage       1.0\n",
      "need into storage     1.0\n",
      "all the space         1.0\n",
      "the into storage      1.0\n",
      "space into storage    1.0\n",
      "we into storage       1.0\n",
      "can into storage      1.0\n",
      "get. into storage     1.0\n",
      "So into storage       1.0\n",
      "if into storage       1.0\n",
      "you into storage      1.0\n",
      "could into storage    1.0\n",
      "just into storage     1.0\n",
      "go into storage       1.0\n",
      "ahead into storage    1.0\n",
      "and into storage      1.0\n",
      "pack into storage     1.0\n",
      "up into storage       1.0\n",
      "your into storage     1.0\n",
      "stuff into storage    1.0\n",
      "and into storage      1.0\n",
      "move into storage     1.0\n",
      "it into storage       1.0\n",
      "down into storage     1.0\n",
      "there, into storage   1.0\n",
      "that would be         1.0\n",
      "would would be        1.0\n",
      "be would be           1.0\n",
      "terrific, would be    1.0\n",
      "OK? would be          1.0\n",
      "Oh, would be          1.0\n",
      "and would be          1.0\n",
      "remember: would be    1.0\n",
      "next would be         1.0\n",
      "Friday... would be    1.0\n",
      "is Hawaiian shirt     1.0\n",
      "Hawaiian Hawaiian shirt  1.0\n",
      "shirt Hawaiian shirt  1.0\n",
      "day. Hawaiian shirt   1.0\n",
      "So, Hawaiian shirt    1.0\n",
      "you Hawaiian shirt    1.0\n",
      "know, Hawaiian shirt  1.0\n",
      "if Hawaiian shirt     1.0\n",
      "you Hawaiian shirt    1.0\n",
      "want Hawaiian shirt   1.0\n",
      "to, Hawaiian shirt    1.0\n",
      "go Hawaiian shirt     1.0\n",
      "ahead Hawaiian shirt  1.0\n",
      "and Hawaiian shirt    1.0\n",
      "wear Hawaiian shirt   1.0\n",
      "a Hawaiian shirt      1.0\n",
      "Hawaiian Hawaiian shirt  1.0\n",
      "shirt Hawaiian shirt  1.0\n",
      "and Hawaiian shirt    1.0\n",
      "jeans. Hawaiian shirt  1.0\n",
      "Oh, Hawaiian shirt    1.0\n",
      "oh, Hawaiian shirt    1.0\n",
      "and Hawaiian shirt    1.0\n",
      "I Hawaiian shirt      1.0\n",
      "almost Hawaiian shirt  1.0\n",
      "forgot. Hawaiian shirt  1.0\n",
      "Ahh, Hawaiian shirt   1.0\n",
      "I'm Hawaiian shirt    1.0\n",
      "also Hawaiian shirt   1.0\n",
      "gonna Hawaiian shirt  1.0\n",
      "need Hawaiian shirt   1.0\n",
      "you Hawaiian shirt    1.0\n",
      "to Hawaiian shirt     1.0\n",
      "go Hawaiian shirt     1.0\n",
      "ahead Hawaiian shirt  1.0\n",
      "and Hawaiian shirt    1.0\n",
      "come Hawaiian shirt   1.0\n",
      "in Hawaiian shirt     1.0\n",
      "on Hawaiian shirt     1.0\n",
      "Sunday, Hawaiian shirt  1.0\n",
      "too... Hawaiian shirt  1.0\n",
      "Hello Hawaiian shirt  1.0\n",
      "Peter, Hawaiian shirt  1.0\n",
      "whats Hawaiian shirt  1.0\n",
      "happening? Hawaiian shirt  1.0\n",
      "Ummm, Hawaiian shirt  1.0\n",
      "I'm Hawaiian shirt    1.0\n",
      "gonna Hawaiian shirt  1.0\n",
      "need Hawaiian shirt   1.0\n",
      "you Hawaiian shirt    1.0\n",
      "to Hawaiian shirt     1.0\n",
      "go Hawaiian shirt     1.0\n",
      "ahead Hawaiian shirt  1.0\n",
      "and Hawaiian shirt    1.0\n",
      "come Hawaiian shirt   1.0\n",
      "in Hawaiian shirt     1.0\n",
      "tomorrow. Hawaiian shirt  1.0\n",
      "So Hawaiian shirt     1.0\n",
      "if Hawaiian shirt     1.0\n",
      "you Hawaiian shirt    1.0\n",
      "could Hawaiian shirt  1.0\n",
      "be Hawaiian shirt     1.0\n",
      "here Hawaiian shirt   1.0\n",
      "around Hawaiian shirt  1.0\n",
      "9 Hawaiian shirt      1.0\n",
      "that Hawaiian shirt   1.0\n",
      "would Hawaiian shirt  1.0\n",
      "be Hawaiian shirt     1.0\n",
      "great, Hawaiian shirt  1.0\n",
      "mmmk... Hawaiian shirt  1.0\n",
      "oh Hawaiian shirt     1.0\n",
      "oh! Hawaiian shirt    1.0\n",
      "and Hawaiian shirt    1.0\n",
      "I Hawaiian shirt      1.0\n",
      "almost Hawaiian shirt  1.0\n",
      "forgot Hawaiian shirt  1.0\n",
      "ahh, Hawaiian shirt   1.0\n",
      "I'm Hawaiian shirt    1.0\n",
      "also Hawaiian shirt   1.0\n",
      "gonna Hawaiian shirt  1.0\n",
      "need Hawaiian shirt   1.0\n",
      "you Hawaiian shirt    1.0\n",
      "to Hawaiian shirt     1.0\n",
      "go Hawaiian shirt     1.0\n",
      "ahead Hawaiian shirt  1.0\n",
      "and Hawaiian shirt    1.0\n",
      "come Hawaiian shirt   1.0\n",
      "in Hawaiian shirt     1.0\n",
      "on Hawaiian shirt     1.0\n",
      "Sunday Hawaiian shirt  1.0\n",
      "too, Hawaiian shirt   1.0\n",
      "kay. Hawaiian shirt   1.0\n",
      "We Hawaiian shirt     1.0\n",
      "ahh Hawaiian shirt    1.0\n",
      "lost Hawaiian shirt   1.0\n",
      "some Hawaiian shirt   1.0\n",
      "people Hawaiian shirt  1.0\n",
      "this Hawaiian shirt   1.0\n",
      "week Hawaiian shirt   1.0\n",
      "and Hawaiian shirt    1.0\n",
      "ah, Hawaiian shirt    1.0\n",
      "we Hawaiian shirt     1.0\n",
      "sorta Hawaiian shirt  1.0\n",
      "need Hawaiian shirt   1.0\n",
      "to Hawaiian shirt     1.0\n",
      "play Hawaiian shirt   1.0\n",
      "catch Hawaiian shirt  1.0\n",
      "up. Hawaiian shirt    1.0\n"
     ]
    }
   ],
   "source": [
    "### Code attempts to extract most common phrases \n",
    "### in groups of 3 from sample text.\n",
    "### Needs work somewhere (maybe in code from previous questions)\n",
    "\n",
    "best_phrases = []\n",
    "words_hit = []\n",
    "words_skipped = []\n",
    "\n",
    "for word_0 in data_list[2:]:\n",
    "    try:\n",
    "        words_hit.append(LaterWords(sample_memo, word_0 , 2))\n",
    "    except ValueError as e:\n",
    "        words_skipped.append(word_0)\n",
    "  \n",
    "    # contains most likely possible 2nd missing words\n",
    "    # for each possible 1st missing words\n",
    "    best_subphrases = {} \n",
    "    \n",
    "    for missing_1st, missing_2nds in cond_prob_tree.iteritems():\n",
    "        best_missing_2nd = max(missing_2nds.iterkeys(),\n",
    "                               key=(lambda key: missing_2nds[key]))\n",
    "        subphrase = missing_1st + ' ' + best_missing_2nd\n",
    "        best_subphrases[subphrase] = missing_2nds[best_missing_2nd]\n",
    "    \n",
    "    part_best_phrase = max(best_subphrases.iterkeys(),\n",
    "                           key=(lambda key: best_subphrases[key]))\n",
    "    best_phrase = word_0 + ' ' + part_best_phrase\n",
    "    best_phrase_prob = best_subphrases[part_best_phrase]\n",
    "    best_phrases.append(tuple([best_phrase, best_phrase_prob]))\n",
    "\n",
    "best_phrases.sort(key=(lambda item: item[1]))\n",
    "    \n",
    "print len(data_list)\n",
    "print len(words_hit)\n",
    "print len(words_skipped)\n",
    "len(best_phrases)\n",
    "for phrase, prob in best_phrases:\n",
    "    print phrase, ' '*(20-len(phrase)) , prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain Knowledge Fill In"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![domain knowledge fill in](mini-project_bayes_natural_language_processing_images/domain_knowledge_fill_in.png)\n",
    "\n",
    "\n",
    "\"If we could encode this all in our classifier, we'd be able to achieve very high levels of accuracy!\""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
