{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Side notes \n",
    "_(code snippets, summaries, resources, etc.)_\n",
    "\n",
    "__Definitions:__\n",
    "- Metric vs. non-metric statistic\n",
    "    - median would be non-metric (ordering of the number matter)\n",
    "    - mean would be metric (magnitudes of the numbers matter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of topics covered\n",
    "![summary of more clustering](more_clustering_images/summary_more_clustering.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Linkage Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm for SLC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SLC is a _Hierarchical Agglomerative Clustering_\n",
    "\n",
    "![SLC algortihm](more_clustering_images/slc_algorithm.png)\n",
    "\n",
    "- Intercluster distance is 0 if two points are connected\n",
    "- Red lines represent order of linkages between points\n",
    "- $d$ can defined in various ways to produce, for example, _average/mean linkage clustering_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running time of SLC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SLC running time](more_clustering_images/slc_running_time.png)\n",
    "\n",
    "- A little less than n<sup>3<sup\\> but left our for big-O notation\n",
    "- Lots of clever ways of bringing this down, like Fibonacci heaps, hash tables etc. \n",
    "\n",
    "Steps in slide above explained:\n",
    "1. Outer loop for connecting 2 points\n",
    "    1. At each iteration, determine which two points are closest to one another by going through all points\n",
    "        - skip distance calculation if two points are connected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issues with SLC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SLC issues](more_clustering_images/slc_issues.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soft Clustering (with Expectation Maximization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ML stands for _maximum likelihood_ in this context\n",
    "\n",
    "![soft clustering](more_clustering_images/soft_clustering.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Likelihood Gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- hidden random variables $z_{k}$ are indicator variables on which cluster $x$ came from\n",
    "- concept of hidden variables breaks up problem in convenient way\n",
    "\n",
    "![ML Gaussian](more_clustering_images/ml_gaussian.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expectation Maximization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Algorithmically similar to k-means\n",
    "- Reminder: ML is uniform and thus would not have any impact on the normalization, and allows us to leave out the prior\n",
    "- Alogithm improves on a probablilistic metric from an error metric\n",
    "\n",
    "![Expectation Maximization](more_clustering_images/expectation_maximization.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EM Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- X marks cluster center (sample mean of cluster)\n",
    "- Green points indicate points with intermediate probabilities\n",
    "- EM is better than SLC because it does not \"force\" green points to be in a particular cluster, or any other point for that matter (although points may have an very high probability of being in one cluster or the other.\n",
    "\n",
    "__1st iteration__\n",
    "\n",
    "![EM example 1](more_clustering_images/em_example_1.png)\n",
    "\n",
    "__2nd iteration__\n",
    "\n",
    "![EM example 1](more_clustering_images/em_example_2.png)\n",
    "\n",
    "__3rd iteration__\n",
    "\n",
    "![EM example 1](more_clustering_images/em_example_3.png)\n",
    "\n",
    "__4th iteration__\n",
    "\n",
    "![EM example 1](more_clustering_images/em_example_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Properties of EM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Does not necessarily have to be applied to a Gaussian random distribution\n",
    "\n",
    "![Properties of EM](more_clustering_images/properties_of_em.png)\n",
    "\n",
    "- Usually gets stuck in a local optima\n",
    "    - Solution: randomly restart\n",
    "- Works with any probability distribution, but must derive steps:\n",
    "    - $E$, i.e. how do you do expectation to work out the probability of the latent variables.\n",
    "    - $M$, i.e. how do you do maximization to use those latent variables to estimate the paramters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desirable clustering properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Properties that we might want in our clustering algorithm\n",
    "\n",
    "![Desirable Clustering Properties](more_clustering_images/desirable_clustering_properties.png)\n",
    "\n",
    "__Clustering Properties Quiz:__\n",
    "Answers explained in [this video](https://classroom.udacity.com/nanodegrees/nd009/parts/0091345407/modules/542278935775460/lessons/5455061279/concepts/6381886680923#)\n",
    "\n",
    "![Clustering Properties Quiz](more_clustering_images/clustering_properties_quiz.png)\n",
    "\n",
    "- Some solutions determined by considering edge cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impossibility Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Impossible for all three to be true one clustering algorithm\n",
    "    - Properties are mutually contradictory\n",
    "\n",
    "![Impossibility Theorem](more_clustering_images/impossibility_theorem.png)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
